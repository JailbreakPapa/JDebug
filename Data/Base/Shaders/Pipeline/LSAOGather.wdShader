[PLATFORMS]
ALL

[PERMUTATIONS]

LSAO_DEPTH_COMPARE
DISTRIBUTED_SSAO_GATHERING
CAMERA_MODE
VERTEX_SHADER_RENDER_TARGET_ARRAY_INDEX

[RENDERSTATE]

DepthTest = false
DepthTestFunc = CompareFunc_Less
DepthWrite = false
CullMode = CullMode_None

[VERTEXSHADER]

#include <Shaders/Pipeline/FullscreenTriangleVertexShader.h>

[GEOMETRYSHADER]

#include <Shaders/Pipeline/FullscreenTriangleStereoGeometryShader.h>

[PIXELSHADER]

#include <Shaders/Pipeline/FullscreenTriangleInterpolator.h>
#include <Shaders/Common/GlobalConstants.h>
#include <Shaders/Common/Common.h>
#include <Shaders/Pipeline/Utils.h>
#include "LSAOConstants.h"

Texture2DArray<float> DepthBuffer : register(t0);

StructuredBuffer<LineInstruction> LineInstructions : register(t1);
Buffer<uint> LineSweepOutputBuffer : register(t2);


// If not defined, all pixels gather all directions, otherwise the work will be distributed to a 3x3 grid.
#if DISTRIBUTED_SSAO_GATHERING
  #define NUM_SAMPLES_PER_PIXEL (NUM_SWEEP_DIRECTIONS_PER_FRAME / 9)
#else
  #define NUM_SAMPLES_PER_PIXEL NUM_SWEEP_DIRECTIONS_PER_FRAME
#endif


// If defined, the two closest samples instead of just one will be taken per direction.
#define TWO_SAMPLES_PER_DIR


//#define ASSERT(condition) if(!(condition)) { return float4(1, 0, 1, 0); }
#define ASSERT(condition)

// Unpacks the sample at sampleIndex and returns the occlusion a its point.
float GetLineSample(uint sampleIndex, uint offset)
{
  uint rawSample = LineSweepOutputBuffer.Load(offset + sampleIndex/2);
  uint sample = rawSample >> (16 * (sampleIndex % 2 == 0));
  sample &= 0xFFFF;
  return f16tof32(sample);
}

float SampleDepth(float2 texCoords)
{
  return DepthBuffer.SampleLevel(PointClampSampler, float3(texCoords, s_ActiveCameraEyeIndex), 0).r;
}

// View-space normal at the given location.
float3 ReconstructNormal(float2 texCoords, float centerDepth)
{
  float2 texelSize = ViewportSize.zw;

  float leftDepth = SampleDepth(texCoords - float2(texelSize.x, 0));
  float topDepth = SampleDepth(texCoords - float2(0, texelSize.y));
  float rightDepth = SampleDepth(texCoords + float2(texelSize.x, 0));
  float bottomDepth = SampleDepth(texCoords + float2(0, texelSize.y));
  float2 normalizedCoords = texCoords * 2.0f - 1.0f;
  return ReconstructViewSpaceNormal(normalizedCoords, centerDepth, leftDepth, rightDepth, topDepth, bottomDepth);
}

// LSAO_DEPTH_COMPARE_DEPTH, hard cutoff at sample distance
float ComputeDistanceCutOffWeight(float centerLinearDepth, float sampleLinearDepth)
{
  return abs(sampleLinearDepth - centerLinearDepth) < DepthCutoffDistance ? 1.0f : 0.0f;
}

// LSAO_DEPTH_COMPARE_NORMAL_AND_SAMPLE_DISTANCE
// If we use two samples and the above depth compare function we addtionally weight each
// sample by its distance to the evaluated center pixel. This gives more weight to samples that
// are closer and thus should be more correct that a sample that was evaluated at a distant location.
float ComputeDistanceWeight(float2 centerPixelPos, float2 samplePixelPos, float sampleDistanceInv)
{
  float toPixel = length(samplePixelPos - centerPixelPos);
  float distWeight = 1.0f - toPixel * sampleDistanceInv;
  return distWeight;
}

// Monolithic weight function and chooses from LSAO_DEPTH_COMPARE options.
// I hope the compiler is smart enough to remove the unused variables.
float ComputeSampleWeight(float2 centerPixelPos, float3 centerPos, float3 viewSpaceNormal, float2 samplePixelPos, float sampleDistanceInv)
{
  float sampleLinearDepth = LinearizeZBufferDepth(DepthBuffer.Load(int4(samplePixelPos, s_ActiveCameraEyeIndex, 0)));
#if LSAO_DEPTH_COMPARE == LSAO_DEPTH_COMPARE_DEPTH
  return ComputeDistanceCutOffWeight(centerPos.z, sampleLinearDepth);
#else
  float2 normalizedCoords = samplePixelPos / ViewportSize.xy * 2.0f - 1.0f;
  float3 samplePos = FastScreenCoordToViewSpaceLinear(normalizedCoords, sampleLinearDepth);
  
  #if LSAO_DEPTH_COMPARE == LSAO_DEPTH_COMPARE_NORMAL
    return ComputeNormalWeight(viewSpaceNormal, centerPos, samplePos, DepthCutoffDistance);
  #elif LSAO_DEPTH_COMPARE == LSAO_DEPTH_COMPARE_NORMAL_AND_SAMPLE_DISTANCE
    float weight = ComputeNormalWeight(viewSpaceNormal, centerPos, samplePos, DepthCutoffDistance);
    #ifdef TWO_SAMPLES_PER_DIR
      weight *= ComputeDistanceWeight(centerPixelPos, samplePixelPos, sampleDistanceInv);
    #endif
    return weight;
  #endif
#endif
}

float4 main(PS_IN input) : SV_Target
{
  #if CAMERA_MODE == CAMERA_MODE_STEREO
    s_ActiveCameraEyeIndex = input.RenderTargetArrayIndex;
  #endif
  uint bufferArrayOffset = (s_ActiveCameraEyeIndex * TotalNumberOfSamples) / 2;

  float2 screenSize = ViewportSize.xy;
  float2 screenSizeSubOne = screenSize - float2(1.0f, 1.0f);
  float2 centerPixelPos = input.TexCoord0 * screenSize;
  float2 pixelPosInv = screenSizeSubOne - centerPixelPos;

  float occlusionAccum = 0.0f;
  float totalWeight = 0.0f;

  float centerDepth = SampleDepth(input.TexCoord0);
  float centerLinearDepth = LinearizeZBufferDepth(centerDepth);
  float3 centerPos = FastScreenCoordToViewSpaceLinear(input.TexCoord0 * 2.0f - 1.0f, centerLinearDepth);
  float3 viewSpaceNormal = ReconstructNormal(input.TexCoord0, centerDepth);

#if DISTRIBUTED_SSAO_GATHERING
  // Hardcoded 3x3 square.
  const uint startDirIdx = ((uint(centerPixelPos.x) % 3) + (uint(centerPixelPos.y) % 3) * 3) * NUM_SAMPLES_PER_PIXEL;
  [unroll] for (int i = 0; i < 4; ++i)
  {
    uint dirIndex = startDirIdx + i;
#else
  [unroll] for (uint dirIndex = 0; dirIndex < NUM_SAMPLES_PER_PIXEL; ++dirIndex)
  {
#endif
    float2 dir = Directions[dirIndex].Direction;
    float sampleDistanceInv = 1.0f / length(dir);
    uint lineInstructionIndex = Directions[dirIndex].LineInstructionOffset;

    // Compute which line is closest to this pixel. See wdScreenSpaceAmbientOcclusionPass::AddLinesForDirection
    // Note that we're using mostly float here instead of int as done by the CPU implementation.
    // This is quite a bit faster on GPU and doesn't suffer any accuracy issues since we're calculating with small integers (way below the 24bit limit).
    float2 lineOrigin;
    float lineSampleNumberFloat = 0.0f;
    {
      // Just like in wdScreenSpaceAmbientOcclusionPass::AddLinesForDirection we try to treat negative directions exactly like positive ones,
      // except for a flip in the lineOrigin.
      float2 absDir = abs(dir);

      float2 virtualPixelPos;
      virtualPixelPos.x = (absDir.x == dir.x) ? centerPixelPos.x : pixelPosInv.x;
      virtualPixelPos.y = (absDir.y == dir.y) ? centerPixelPos.y : pixelPosInv.y;

      // To avoid branch and code duplication:
      uint domAxis = (absDir.x > absDir.y) ? 0 : 1; // dominant axis
      uint secAxis = 1 - domAxis; // secondary axis

      float numStepsToLeftBorder = virtualPixelPos[domAxis] / absDir[domAxis];
      float secAtBorder = virtualPixelPos[secAxis] - numStepsToLeftBorder * absDir[secAxis];
      lineInstructionIndex += uint((screenSizeSubOne[secAxis] - secAtBorder) / LineToLinePixelOffset + 0.5f);
      lineOrigin = LineInstructions[lineInstructionIndex].FirstSamplePos;
      lineSampleNumberFloat = (centerPixelPos[domAxis] - lineOrigin[domAxis]) / dir[domAxis];
    }

    // Line instructions know the direction they belong to, use this to make sure that we're touching the right one.
    ASSERT((LineInstructions[lineInstructionIndex].LineDirIndex_totalWeight & 0xFFFF) == uint(dirIndex))

    // If everything went as planned, lineSampleNumber is never smaller than -1
    // Beeing smaller zero means that the start is "in front" of the pixel which can happen due to jittering.
    ASSERT((int)lineSampleNumberFloat >= -1);

    // Fetch two closest samples on this line.
    // Taking two instead of one cancels out most artifacts and further selection through depth comparision doesn't seem to be necesary anymore
#ifndef TWO_SAMPLES_PER_DIR
    lineSampleNumberFloat = round(lineSampleNumberFloat);
#endif

    uint lineSampleNumberFloor = (uint)lineSampleNumberFloat;
    uint sampleIndex = lineSampleNumberFloor + LineInstructions[lineInstructionIndex].LineSweepOutputBufferOffset;

    // Apply weighted with depth filter.
    float2 samplePixelPos = lineOrigin + lineSampleNumberFloor * dir;
    float weight = ComputeSampleWeight(centerPixelPos, centerPos, viewSpaceNormal, samplePixelPos, sampleDistanceInv);   
    // Any conditional here will only make it slower as the number of pixels that would be discarded
    // is generally really small unless your image only contains noise and no structure.
    {
      float sample = GetLineSample(sampleIndex, bufferArrayOffset);
      occlusionAccum += sample * weight;
      totalWeight += weight;
    }
    
#ifdef TWO_SAMPLES_PER_DIR
    // Second sample for better quality.
    samplePixelPos += dir; // = lineOrigin + lineSampleNumberCeil * dir;
    weight = ComputeSampleWeight(centerPixelPos, centerPos, viewSpaceNormal, samplePixelPos, sampleDistanceInv);
    {
      ++sampleIndex;
      float sample = GetLineSample(sampleIndex, bufferArrayOffset);
      occlusionAccum += sample * weight;
      totalWeight += weight;
    }
#endif
  }

  float output = 1.0f;
  if (totalWeight > 0.0f)
     output = saturate(1.0f - occlusionAccum / totalWeight);
  return float4(output.x, centerLinearDepth, 0, 1);
  //return output.xxxx;
}
